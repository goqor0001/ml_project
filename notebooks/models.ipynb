{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import spacy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../final_data.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle dataset and split into train, valoidation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19867 entries, 0 to 19866\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   posterID        19867 non-null  object \n",
      " 1   Genre           19835 non-null  object \n",
      " 2   overview        19833 non-null  object \n",
      " 3   IMDB Score      19860 non-null  float64\n",
      " 4   director        19867 non-null  object \n",
      " 5   actors          18912 non-null  object \n",
      " 6   runtime         19865 non-null  float64\n",
      " 7   num_faces       19867 non-null  float64\n",
      " 8   brightness      19867 non-null  float64\n",
      " 9   saturation      19867 non-null  float64\n",
      " 10  hue             19867 non-null  float64\n",
      " 11  brightness_sd   19867 non-null  float64\n",
      " 12  saturation_sd   19867 non-null  float64\n",
      " 13  hue_sd          19867 non-null  float64\n",
      " 14  blue            19867 non-null  float64\n",
      " 15  blue_sd         19867 non-null  float64\n",
      " 16  green           19867 non-null  float64\n",
      " 17  green_sd        19867 non-null  float64\n",
      " 18  red             19867 non-null  float64\n",
      " 19  red_sd          19867 non-null  float64\n",
      "dtypes: float64(15), object(5)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'IMDB Score': 'imdb_score'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['posterID', 'Genre', 'overview', 'director', 'actors',\n",
    "       'runtime', 'num_faces', 'brightness', 'saturation', 'hue',\n",
    "       'brightness_sd', 'saturation_sd ', 'hue_sd', 'blue', 'blue_sd', 'green',\n",
    "       'green_sd', 'red', 'red_sd ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data, train_size=0.7):\n",
    "    X_train, RX = train_test_split(data, test_size=1-train_size, random_state=0)\n",
    "    X_val, X_test = train_test_split(RX, test_size=0.5, random_state=0)\n",
    "    \n",
    "    return X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test = split_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13194, 20)\n",
      "(2828, 20)\n",
      "(2828, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('../data/X_train.csv', index=False)\n",
    "X_val.to_csv('../data/X_val.csv', index=False)\n",
    "X_test.to_csv('../data/X_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/X_train.csv', encoding='latin1')\n",
    "X_val = pd.read_csv('../data/X_val.csv', encoding='latin1')\n",
    "X_test = pd.read_csv('../data/X_test.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_words(s, tokenizer=None):\n",
    "    if tokenizer:\n",
    "        words = tokenizer(s)\n",
    "        return [i.text for i in words]\n",
    "    else:\n",
    "        return s.lower().split('|')\n",
    "\n",
    "def get_dict(data, min_count=5, tokenizer=None):\n",
    "    count = {}\n",
    "    for s in data:\n",
    "        words = split_words(s, tokenizer)\n",
    "        for word in set(words):\n",
    "            if word in count:\n",
    "                count[word] += 1\n",
    "            else:\n",
    "                count[word] = 1\n",
    "                \n",
    "    for word in list(count.keys()):\n",
    "        if count[word] < min_count:\n",
    "            del count[word]\n",
    "            \n",
    "    for i, word in enumerate(count.keys()):\n",
    "        count[word] = i\n",
    "    \n",
    "    return count\n",
    "\n",
    "def transform_text(data, word_count, tokenizer= None):\n",
    "    tr = np.zeros((len(data), len(word_count)))\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        words = split_words(data[i], tokenizer)\n",
    "        for word in words:\n",
    "            if word in word_count:\n",
    "                tr[i][word_count[word]] += 1\n",
    "            \n",
    "    return tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13194, 23)\n",
      "(2828, 23)\n",
      "(2828, 23)\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "genre_count = get_dict(X_train.Genre.astype(str))\n",
    "\n",
    "genre_train = transform_text(X_train.Genre, genre_count)\n",
    "genre_val = transform_text(X_val.Genre, genre_count)\n",
    "genre_test = transform_text(X_test.Genre, genre_count)\n",
    "\n",
    "print(genre_train.shape)\n",
    "print(genre_val.shape)\n",
    "print(genre_test.shape)\n",
    "print(len(genre_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13194, 491)\n",
      "(2828, 491)\n",
      "(2828, 491)\n",
      "491\n"
     ]
    }
   ],
   "source": [
    "dir_count = get_dict(X_train.director.astype(str))\n",
    "\n",
    "dir_train = transform_text(X_train.director, dir_count)\n",
    "dir_val = transform_text(X_val.director, dir_count)\n",
    "dir_test = transform_text(X_test.director, dir_count)\n",
    "\n",
    "print(dir_train.shape)\n",
    "print(dir_val.shape)\n",
    "print(dir_test.shape)\n",
    "print(len(dir_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13194, 1671)\n",
      "(2828, 1671)\n",
      "(2828, 1671)\n",
      "1671\n"
     ]
    }
   ],
   "source": [
    "actor_count = get_dict(X_train.actors.astype(str))\n",
    "\n",
    "actor_train = transform_text(X_train.actors, actor_count)\n",
    "actor_val = transform_text(X_val.actors, actor_count)\n",
    "actor_test = transform_text(X_test.actors, actor_count)\n",
    "\n",
    "print(actor_train.shape)\n",
    "print(actor_val.shape)\n",
    "print(actor_test.shape)\n",
    "print(len(actor_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13194, 3712)\n",
      "(2828, 3712)\n",
      "(2828, 3712)\n",
      "3712\n"
     ]
    }
   ],
   "source": [
    "tokenizer = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"ner\"])\n",
    "\n",
    "overview_count = get_dict(X_train.overview.astype(str), min_count=20, tokenizer=tokenizer)\n",
    "\n",
    "overview_train = transform_text(X_train.overview, overview_count, tokenizer=tokenizer)\n",
    "overview_val = transform_text(X_val.overview, overview_count, tokenizer=tokenizer)\n",
    "overview_test = transform_text(X_test.overview, overview_count, tokenizer=tokenizer)\n",
    "\n",
    "print(overview_train.shape)\n",
    "print(overview_val.shape)\n",
    "print(overview_test.shape)\n",
    "print(len(overview_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =  pd.concat([X_train, pd.DataFrame(genre_train, columns=genre_count.keys()),\n",
    "          pd.DataFrame(dir_train, columns=dir_count.keys()),\n",
    "          pd.DataFrame(actor_train, columns=actor_count.keys()),\n",
    "          pd.DataFrame(overview_train, columns=overview_count.keys())], axis = 1)\n",
    "\n",
    "val_data =  pd.concat([X_val, pd.DataFrame(genre_val, columns=genre_count.keys()),\n",
    "          pd.DataFrame(dir_val, columns=dir_count.keys()),\n",
    "          pd.DataFrame(actor_val, columns=actor_count.keys()),\n",
    "          pd.DataFrame(overview_val, columns=overview_count.keys())], axis = 1)\n",
    "\n",
    "test_data =  pd.concat([X_test, pd.DataFrame(genre_test, columns=genre_count.keys()),\n",
    "          pd.DataFrame(dir_test, columns=dir_count.keys()),\n",
    "          pd.DataFrame(actor_test, columns=actor_count.keys()),\n",
    "          pd.DataFrame(overview_test, columns=overview_count.keys())], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=['Genre', 'overview', 'director', 'actors'])\n",
    "val_data = val_data.drop(columns=['Genre', 'overview', 'director', 'actors'])\n",
    "test_data = test_data.drop(columns=['Genre', 'overview', 'director', 'actors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13194, 5910)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('../data/train_final.csv', index=False)\n",
    "val_data.to_csv('../data/val_final.csv', index=False)\n",
    "test_data.to_csv('../data/test_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train_final.csv', encoding='latin1')\n",
    "val_data = pd.read_csv('../data/val_final.csv', encoding='latin1')\n",
    "test_data = pd.read_csv('../data/test_final.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posterID</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>runtime</th>\n",
       "      <th>num_faces</th>\n",
       "      <th>brightness</th>\n",
       "      <th>saturation</th>\n",
       "      <th>hue</th>\n",
       "      <th>brightness_sd</th>\n",
       "      <th>saturation_sd</th>\n",
       "      <th>hue_sd</th>\n",
       "      <th>...</th>\n",
       "      <th>subway</th>\n",
       "      <th>cities</th>\n",
       "      <th>excitement</th>\n",
       "      <th>monstrous</th>\n",
       "      <th>May</th>\n",
       "      <th>traps</th>\n",
       "      <th>traffic</th>\n",
       "      <th>heir</th>\n",
       "      <th>fearless</th>\n",
       "      <th>eliminate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118747.jpg</td>\n",
       "      <td>4.8</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.583033</td>\n",
       "      <td>62.248667</td>\n",
       "      <td>120.589860</td>\n",
       "      <td>98.161753</td>\n",
       "      <td>57.907563</td>\n",
       "      <td>40.760182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118002.jpg</td>\n",
       "      <td>5.2</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.587666</td>\n",
       "      <td>83.177751</td>\n",
       "      <td>51.144231</td>\n",
       "      <td>56.498982</td>\n",
       "      <td>55.874362</td>\n",
       "      <td>60.854732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245407.jpg</td>\n",
       "      <td>5.9</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.694481</td>\n",
       "      <td>57.421970</td>\n",
       "      <td>43.001210</td>\n",
       "      <td>49.501003</td>\n",
       "      <td>59.513949</td>\n",
       "      <td>53.704714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101702.jpg</td>\n",
       "      <td>2.7</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.594473</td>\n",
       "      <td>85.856077</td>\n",
       "      <td>39.782188</td>\n",
       "      <td>84.970622</td>\n",
       "      <td>74.797138</td>\n",
       "      <td>51.705340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4717798.jpg</td>\n",
       "      <td>6.5</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.897532</td>\n",
       "      <td>141.154133</td>\n",
       "      <td>56.524746</td>\n",
       "      <td>70.349874</td>\n",
       "      <td>78.879589</td>\n",
       "      <td>53.644487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13189</th>\n",
       "      <td>453508.jpg</td>\n",
       "      <td>8.6</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.180970</td>\n",
       "      <td>143.553735</td>\n",
       "      <td>32.213240</td>\n",
       "      <td>58.971763</td>\n",
       "      <td>47.963068</td>\n",
       "      <td>27.805569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13190</th>\n",
       "      <td>197256.jpg</td>\n",
       "      <td>5.7</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.603227</td>\n",
       "      <td>61.878834</td>\n",
       "      <td>66.051132</td>\n",
       "      <td>94.566402</td>\n",
       "      <td>79.445453</td>\n",
       "      <td>58.006236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13191</th>\n",
       "      <td>1534084.jpg</td>\n",
       "      <td>4.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.397737</td>\n",
       "      <td>58.010025</td>\n",
       "      <td>27.310645</td>\n",
       "      <td>66.997014</td>\n",
       "      <td>47.144934</td>\n",
       "      <td>20.478903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13192</th>\n",
       "      <td>1621446.jpg</td>\n",
       "      <td>4.3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.851361</td>\n",
       "      <td>62.678879</td>\n",
       "      <td>80.704260</td>\n",
       "      <td>79.846216</td>\n",
       "      <td>63.411827</td>\n",
       "      <td>43.294419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13193</th>\n",
       "      <td>93036.jpg</td>\n",
       "      <td>5.7</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.545596</td>\n",
       "      <td>153.911001</td>\n",
       "      <td>76.686034</td>\n",
       "      <td>90.484114</td>\n",
       "      <td>81.840475</td>\n",
       "      <td>54.262379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13194 rows × 5910 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          posterID  imdb_score  runtime  num_faces  brightness  saturation  \\\n",
       "0       118747.jpg         4.8    123.0        0.0  121.583033   62.248667   \n",
       "1       118002.jpg         5.2     96.0        0.0   72.587666   83.177751   \n",
       "2       245407.jpg         5.9    112.0        0.0  221.694481   57.421970   \n",
       "3       101702.jpg         2.7     97.0        0.0  164.594473   85.856077   \n",
       "4      4717798.jpg         6.5     79.0        0.0  131.897532  141.154133   \n",
       "...            ...         ...      ...        ...         ...         ...   \n",
       "13189   453508.jpg         8.6     81.0        0.0  130.180970  143.553735   \n",
       "13190   197256.jpg         5.7    105.0        0.0   96.603227   61.878834   \n",
       "13191  1534084.jpg         4.5    100.0        0.0  152.397737   58.010025   \n",
       "13192  1621446.jpg         4.3     90.0        0.0   68.851361   62.678879   \n",
       "13193    93036.jpg         5.7     93.0        0.0  119.545596  153.911001   \n",
       "\n",
       "              hue  brightness_sd  saturation_sd      hue_sd  ...  subway  \\\n",
       "0      120.589860      98.161753       57.907563  40.760182  ...     0.0   \n",
       "1       51.144231      56.498982       55.874362  60.854732  ...     0.0   \n",
       "2       43.001210      49.501003       59.513949  53.704714  ...     0.0   \n",
       "3       39.782188      84.970622       74.797138  51.705340  ...     0.0   \n",
       "4       56.524746      70.349874       78.879589  53.644487  ...     0.0   \n",
       "...           ...            ...             ...        ...  ...     ...   \n",
       "13189   32.213240      58.971763       47.963068  27.805569  ...     0.0   \n",
       "13190   66.051132      94.566402       79.445453  58.006236  ...     0.0   \n",
       "13191   27.310645      66.997014       47.144934  20.478903  ...     0.0   \n",
       "13192   80.704260      79.846216       63.411827  43.294419  ...     0.0   \n",
       "13193   76.686034      90.484114       81.840475  54.262379  ...     0.0   \n",
       "\n",
       "       cities  excitement  monstrous  May  traps  traffic  heir  fearless  \\\n",
       "0         0.0         0.0        0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "1         0.0         0.0        0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "2         0.0         0.0        0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "3         0.0         0.0        0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "4         0.0         0.0        0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "...       ...         ...        ...  ...    ...      ...   ...       ...   \n",
       "13189     0.0         0.0        0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "13190     0.0         0.0        0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "13191     0.0         0.0        0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "13192     0.0         0.0        0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "13193     0.0         0.0        0.0  0.0    0.0      0.0   0.0       0.0   \n",
       "\n",
       "       eliminate  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "...          ...  \n",
       "13189        0.0  \n",
       "13190        0.0  \n",
       "13191        0.0  \n",
       "13192        0.0  \n",
       "13193        0.0  \n",
       "\n",
       "[13194 rows x 5910 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['runtime','num_faces','hue','hue_sd','saturation','saturation_sd ','brightness','brightness_sd',\n",
    "            'blue','blue_sd','green','green_sd','red','red_sd ']:\n",
    "    mean_feature = np.mean(train_data[col])\n",
    "    sd_feature = np.std(train_data[col])\n",
    "    \n",
    "    if sd_feature != 0:\n",
    "        train_data[col] = (train_data[col] - mean_feature) / sd_feature\n",
    "        val_data[col] = (val_data[col] - mean_feature) / sd_feature\n",
    "        test_data[col] = (test_data[col] - mean_feature) / sd_feature\n",
    "    else:\n",
    "        train_data[col] = (train_data[col] - mean_feature) \n",
    "        val_data[col] = (val_data[col] - mean_feature) \n",
    "        test_data[col] = (test_data[col] - mean_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posterID</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>runtime</th>\n",
       "      <th>num_faces</th>\n",
       "      <th>brightness</th>\n",
       "      <th>saturation</th>\n",
       "      <th>hue</th>\n",
       "      <th>brightness_sd</th>\n",
       "      <th>saturation_sd</th>\n",
       "      <th>hue_sd</th>\n",
       "      <th>...</th>\n",
       "      <th>subway</th>\n",
       "      <th>cities</th>\n",
       "      <th>excitement</th>\n",
       "      <th>monstrous</th>\n",
       "      <th>May</th>\n",
       "      <th>traps</th>\n",
       "      <th>traffic</th>\n",
       "      <th>heir</th>\n",
       "      <th>fearless</th>\n",
       "      <th>eliminate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118747.jpg</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.783686</td>\n",
       "      <td>-0.216658</td>\n",
       "      <td>-0.211632</td>\n",
       "      <td>-0.832558</td>\n",
       "      <td>2.121743</td>\n",
       "      <td>1.853820</td>\n",
       "      <td>-0.387582</td>\n",
       "      <td>-0.339980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118002.jpg</td>\n",
       "      <td>5.2</td>\n",
       "      <td>-0.044494</td>\n",
       "      <td>-0.216658</td>\n",
       "      <td>-1.197686</td>\n",
       "      <td>-0.371092</td>\n",
       "      <td>-0.279790</td>\n",
       "      <td>-0.896663</td>\n",
       "      <td>-0.498212</td>\n",
       "      <td>0.927495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245407.jpg</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.446279</td>\n",
       "      <td>-0.216658</td>\n",
       "      <td>1.803157</td>\n",
       "      <td>-0.938981</td>\n",
       "      <td>-0.561388</td>\n",
       "      <td>-1.358654</td>\n",
       "      <td>-0.300175</td>\n",
       "      <td>0.476504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101702.jpg</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-0.013821</td>\n",
       "      <td>-0.216658</td>\n",
       "      <td>0.653993</td>\n",
       "      <td>-0.312038</td>\n",
       "      <td>-0.672706</td>\n",
       "      <td>0.982971</td>\n",
       "      <td>0.531417</td>\n",
       "      <td>0.350392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4717798.jpg</td>\n",
       "      <td>6.5</td>\n",
       "      <td>-0.565941</td>\n",
       "      <td>-0.216658</td>\n",
       "      <td>-0.004048</td>\n",
       "      <td>0.907230</td>\n",
       "      <td>-0.093724</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.753552</td>\n",
       "      <td>0.472705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13189</th>\n",
       "      <td>453508.jpg</td>\n",
       "      <td>8.6</td>\n",
       "      <td>-0.504594</td>\n",
       "      <td>-0.216658</td>\n",
       "      <td>-0.038594</td>\n",
       "      <td>0.960138</td>\n",
       "      <td>-0.934452</td>\n",
       "      <td>-0.733416</td>\n",
       "      <td>-0.928683</td>\n",
       "      <td>-1.157100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13190</th>\n",
       "      <td>197256.jpg</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.231566</td>\n",
       "      <td>-0.216658</td>\n",
       "      <td>-0.714362</td>\n",
       "      <td>-0.840712</td>\n",
       "      <td>0.235713</td>\n",
       "      <td>1.616463</td>\n",
       "      <td>0.784342</td>\n",
       "      <td>0.747825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13191</th>\n",
       "      <td>1534084.jpg</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.078199</td>\n",
       "      <td>-0.216658</td>\n",
       "      <td>0.408528</td>\n",
       "      <td>-0.926015</td>\n",
       "      <td>-1.103991</td>\n",
       "      <td>-0.203606</td>\n",
       "      <td>-0.973200</td>\n",
       "      <td>-1.619233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13192</th>\n",
       "      <td>1621446.jpg</td>\n",
       "      <td>4.3</td>\n",
       "      <td>-0.228534</td>\n",
       "      <td>-0.216658</td>\n",
       "      <td>-1.272881</td>\n",
       "      <td>-0.823072</td>\n",
       "      <td>0.742440</td>\n",
       "      <td>0.644669</td>\n",
       "      <td>-0.088083</td>\n",
       "      <td>-0.180132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13193</th>\n",
       "      <td>93036.jpg</td>\n",
       "      <td>5.7</td>\n",
       "      <td>-0.136514</td>\n",
       "      <td>-0.216658</td>\n",
       "      <td>-0.252636</td>\n",
       "      <td>1.188506</td>\n",
       "      <td>0.603484</td>\n",
       "      <td>1.346960</td>\n",
       "      <td>0.914660</td>\n",
       "      <td>0.511679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13194 rows × 5910 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          posterID  imdb_score   runtime  num_faces  brightness  saturation  \\\n",
       "0       118747.jpg         4.8  0.783686  -0.216658   -0.211632   -0.832558   \n",
       "1       118002.jpg         5.2 -0.044494  -0.216658   -1.197686   -0.371092   \n",
       "2       245407.jpg         5.9  0.446279  -0.216658    1.803157   -0.938981   \n",
       "3       101702.jpg         2.7 -0.013821  -0.216658    0.653993   -0.312038   \n",
       "4      4717798.jpg         6.5 -0.565941  -0.216658   -0.004048    0.907230   \n",
       "...            ...         ...       ...        ...         ...         ...   \n",
       "13189   453508.jpg         8.6 -0.504594  -0.216658   -0.038594    0.960138   \n",
       "13190   197256.jpg         5.7  0.231566  -0.216658   -0.714362   -0.840712   \n",
       "13191  1534084.jpg         4.5  0.078199  -0.216658    0.408528   -0.926015   \n",
       "13192  1621446.jpg         4.3 -0.228534  -0.216658   -1.272881   -0.823072   \n",
       "13193    93036.jpg         5.7 -0.136514  -0.216658   -0.252636    1.188506   \n",
       "\n",
       "            hue  brightness_sd  saturation_sd     hue_sd  ...  subway  cities  \\\n",
       "0      2.121743       1.853820       -0.387582 -0.339980  ...     0.0     0.0   \n",
       "1     -0.279790      -0.896663       -0.498212  0.927495  ...     0.0     0.0   \n",
       "2     -0.561388      -1.358654       -0.300175  0.476504  ...     0.0     0.0   \n",
       "3     -0.672706       0.982971        0.531417  0.350392  ...     0.0     0.0   \n",
       "4     -0.093724       0.017742        0.753552  0.472705  ...     0.0     0.0   \n",
       "...         ...            ...             ...       ...  ...     ...     ...   \n",
       "13189 -0.934452      -0.733416       -0.928683 -1.157100  ...     0.0     0.0   \n",
       "13190  0.235713       1.616463        0.784342  0.747825  ...     0.0     0.0   \n",
       "13191 -1.103991      -0.203606       -0.973200 -1.619233  ...     0.0     0.0   \n",
       "13192  0.742440       0.644669       -0.088083 -0.180132  ...     0.0     0.0   \n",
       "13193  0.603484       1.346960        0.914660  0.511679  ...     0.0     0.0   \n",
       "\n",
       "       excitement  monstrous  May  traps  traffic  heir  fearless  eliminate  \n",
       "0             0.0        0.0  0.0    0.0      0.0   0.0       0.0        0.0  \n",
       "1             0.0        0.0  0.0    0.0      0.0   0.0       0.0        0.0  \n",
       "2             0.0        0.0  0.0    0.0      0.0   0.0       0.0        0.0  \n",
       "3             0.0        0.0  0.0    0.0      0.0   0.0       0.0        0.0  \n",
       "4             0.0        0.0  0.0    0.0      0.0   0.0       0.0        0.0  \n",
       "...           ...        ...  ...    ...      ...   ...       ...        ...  \n",
       "13189         0.0        0.0  0.0    0.0      0.0   0.0       0.0        0.0  \n",
       "13190         0.0        0.0  0.0    0.0      0.0   0.0       0.0        0.0  \n",
       "13191         0.0        0.0  0.0    0.0      0.0   0.0       0.0        0.0  \n",
       "13192         0.0        0.0  0.0    0.0      0.0   0.0       0.0        0.0  \n",
       "13193         0.0        0.0  0.0    0.0      0.0   0.0       0.0        0.0  \n",
       "\n",
       "[13194 rows x 5910 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4771817495212598\n",
      "1.4264534852595883\n",
      "1.4920414168987786\n"
     ]
    }
   ],
   "source": [
    "print(np.cov(train_data.imdb_score))\n",
    "print(np.cov(val_data.imdb_score))\n",
    "print(np.cov(test_data.imdb_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_data.drop(columns=['imdb_score', 'posterID'])\n",
    "val_X = val_data.drop(columns=['imdb_score', 'posterID'])\n",
    "test_X = test_data.drop(columns=['imdb_score', 'posterID'])\n",
    "train_y = train_data.imdb_score\n",
    "val_y = val_data.imdb_score\n",
    "test_y = test_data.imdb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classified to the nearest pt in {1, 3, 5, 7, 9}\n",
    "def to_5_classes(y): \n",
    "    classes = np.ceil(y/2)\n",
    "    return classes\n",
    "\n",
    "def cls_5_to_value(cls):\n",
    "    new_y = cls * 2 - 1\n",
    "    return new_y\n",
    "\n",
    "# classified to the nearest pt in {0.5, 1.5, 2.5, ... , 8.5, 9.5}\n",
    "def to_10_classes(y):\n",
    "    classes = np.ceil(y)\n",
    "    return classes\n",
    "\n",
    "def cls_10_to_value(cls):\n",
    "    new_y = cls * 1 - 0.5\n",
    "    return new_y\n",
    "  \n",
    "# classified to the nearest pt in {0.25, 0.75, 1.25, 1.75, ... , 9.25, 9.75}\n",
    "def to_20_classes(y):\n",
    "    classes = np.ceil(y*2)\n",
    "    return classes\n",
    "\n",
    "def cls_20_to_value(cls):\n",
    "    new_y = cls * (1/2) - 0.25\n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_5_cls = train_y.apply(to_5_classes)\n",
    "train_y_10_cls = train_y.apply(to_10_classes)\n",
    "train_y_20_cls = train_y.apply(to_20_classes)\n",
    "\n",
    "val_y_5_cls = val_y.apply(to_5_classes)\n",
    "val_y_10_cls = val_y.apply(to_10_classes)\n",
    "val_y_20_cls = val_y.apply(to_20_classes)\n",
    "\n",
    "test_y_5_cls = test_y.apply(to_5_classes)\n",
    "test_y_10_cls = test_y.apply(to_10_classes)\n",
    "test_y_20_cls = test_y.apply(to_20_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r^2:  0.7043745159228347\n",
      "train mse:  0.4366594719572778\n",
      "valid r^2:  0.0058534409210745375\n",
      "valid mse:  1.4176023729169114\n",
      "test r^2:  0.06682427295388171\n",
      "test mse:  1.391844494240012\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression(normalize=True).fit(train_X, train_y)\n",
    "\n",
    "print('train r^2: ', reg.score(train_X, train_y))\n",
    "print('train mse: ', mean_squared_error(reg.predict(train_X), train_y))\n",
    "\n",
    "print('valid r^2: ', reg.score(val_X, val_y))\n",
    "print('valid mse: ', mean_squared_error(reg.predict(val_X), val_y))\n",
    "\n",
    "print('test r^2: ', reg.score(test_X, test_y))\n",
    "print('test mse: ', mean_squared_error(reg.predict(test_X), test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train r^2:  0.6389160207073561\n",
      "train mse:  0.5333462377993188\n",
      "valid r^2:  0.28712903556613334\n",
      "valid mse:  1.016517697049925\n",
      "test r^2:  0.34131220992775924\n",
      "test mse:  0.9824419425665801\n"
     ]
    }
   ],
   "source": [
    "ridgeReg = Ridge(alpha = 10, random_state = 0).fit(train_X, train_y)\n",
    "\n",
    "print('train r^2: ', ridgeReg.score(train_X, train_y))\n",
    "print('train mse: ', mean_squared_error(ridgeReg.predict(train_X), train_y))\n",
    "\n",
    "print('valid r^2: ', ridgeReg.score(val_X, val_y))\n",
    "print('valid mse: ', mean_squared_error(ridgeReg.predict(val_X), val_y))\n",
    "\n",
    "print('test r^2: ', ridgeReg.score(test_X, test_y))\n",
    "print('test mse: ', mean_squared_error(ridgeReg.predict(test_X), test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8614521752311657\n",
      "Train MSE:  0.6599969683189328\n",
      "Valid accuracy:  0.5753182461103253\n",
      "Valid MSE:  2.113154172560113\n",
      "Test accuracy:  0.5823903818953324\n",
      "Test MSE:  2.0438472418670437\n"
     ]
    }
   ],
   "source": [
    "logReg_5_cls = LogisticRegression(penalty='none', solver='lbfgs',multi_class='multinomial').fit(train_X, train_y_5_cls)\n",
    "\n",
    "train_y_5_pred = np.apply_along_axis(cls_5_to_value, 0, logReg_5_cls.predict(train_X))\n",
    "val_y_5_pred = np.apply_along_axis(cls_5_to_value, 0, logReg_5_cls.predict(val_X))\n",
    "test_y_5_pred = np.apply_along_axis(cls_5_to_value, 0, logReg_5_cls.predict(test_X))\n",
    "\n",
    "print('Train accuracy: ', logReg_5_cls.score(train_X, train_y_5_cls))\n",
    "print('Train MSE: ', mean_squared_error(train_y_5_pred, train_y_5_cls.apply(cls_5_to_value)))\n",
    "\n",
    "print('Valid accuracy: ', logReg_5_cls.score(val_X, val_y_5_cls))\n",
    "print('Valid MSE: ', mean_squared_error(val_y_5_pred, val_y_5_cls.apply(cls_5_to_value)))\n",
    "\n",
    "print('Test accuracy: ', logReg_5_cls.score(test_X, test_y_5_cls))\n",
    "print('Test MSE: ', mean_squared_error(test_y_5_pred, test_y_5_cls.apply(cls_5_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grigor/anaconda3/envs/work/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:760: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7051690162194937\n",
      "Train MSE:  0.7668637259360316\n",
      "Valid accuracy:  0.33734087694483733\n",
      "Valid MSE:  1.5792079207920793\n",
      "Test accuracy:  0.3497171145685997\n",
      "Test MSE:  1.5484441301272984\n"
     ]
    }
   ],
   "source": [
    "logReg_10_cls = LogisticRegression(penalty='none', solver='lbfgs',multi_class='multinomial').fit(train_X, train_y_10_cls)\n",
    "\n",
    "train_y_10_pred = np.apply_along_axis(cls_10_to_value, 0, logReg_10_cls.predict(train_X))\n",
    "val_y_10_pred = np.apply_along_axis(cls_10_to_value, 0, logReg_10_cls.predict(val_X))\n",
    "test_y_10_pred = np.apply_along_axis(cls_10_to_value, 0, logReg_10_cls.predict(test_X))\n",
    "\n",
    "print('Train accuracy: ', logReg_10_cls.score(train_X, train_y_10_cls))\n",
    "print('Train MSE: ', mean_squared_error(train_y_10_pred, train_y_10_cls.apply(cls_10_to_value)))\n",
    "\n",
    "print('Valid accuracy: ', logReg_10_cls.score(val_X, val_y_10_cls))\n",
    "print('Valid MSE: ', mean_squared_error(val_y_10_pred, val_y_10_cls.apply(cls_10_to_value)))\n",
    "\n",
    "print('Test accuracy: ', logReg_10_cls.score(test_X, test_y_10_cls))\n",
    "print('Test MSE: ', mean_squared_error(test_y_10_pred, test_y_10_cls.apply(cls_10_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grigor/anaconda3/envs/work/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:760: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6414279217826284\n",
      "Train MSE:  0.7121608306806124\n",
      "Valid accuracy:  0.1934229137199434\n",
      "Valid MSE:  1.4272454031117396\n",
      "Test accuracy:  0.18705799151343705\n",
      "Test MSE:  1.458981612446959\n"
     ]
    }
   ],
   "source": [
    "logReg_20_cls = LogisticRegression(penalty='none', solver='lbfgs',multi_class='multinomial').fit(train_X, train_y_20_cls)\n",
    "\n",
    "train_y_20_pred = np.apply_along_axis(cls_20_to_value, 0, logReg_20_cls.predict(train_X))\n",
    "val_y_20_pred = np.apply_along_axis(cls_20_to_value, 0, logReg_20_cls.predict(val_X))\n",
    "test_y_20_pred = np.apply_along_axis(cls_20_to_value, 0, logReg_20_cls.predict(test_X))\n",
    "\n",
    "print('Train accuracy: ', logReg_20_cls.score(train_X, train_y_20_cls))\n",
    "print('Train MSE: ', mean_squared_error(train_y_20_pred, train_y_20_cls.apply(cls_20_to_value)))\n",
    "\n",
    "print('Valid accuracy: ', logReg_20_cls.score(val_X, val_y_20_cls))\n",
    "print('Valid MSE: ', mean_squared_error(val_y_20_pred, val_y_20_cls.apply(cls_20_to_value)))\n",
    "\n",
    "print('Test accuracy: ', logReg_20_cls.score(test_X, test_y_20_cls))\n",
    "print('Test MSE: ', mean_squared_error(test_y_20_pred, test_y_20_cls.apply(cls_20_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grigor/anaconda3/envs/work/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:760: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8009701379414885\n",
      "Train MSE:  0.9507351826587843\n",
      "Valid accuracy:  0.6145685997171145\n",
      "Valid MSE:  1.7736916548797736\n",
      "Test accuracy:  0.632956152758133\n",
      "Test MSE:  1.7001414427157002\n"
     ]
    }
   ],
   "source": [
    "# Regularization c = 1/alpha = 0.1\n",
    "logRegL2_5_cls = LogisticRegression(penalty='l2', C = 0.1, solver='lbfgs',multi_class='multinomial').fit(train_X, train_y_5_cls)\n",
    "\n",
    "train_y_5_pred = np.apply_along_axis(cls_5_to_value, 0, logRegL2_5_cls.predict(train_X))\n",
    "val_y_5_pred = np.apply_along_axis(cls_5_to_value, 0, logRegL2_5_cls.predict(val_X))\n",
    "test_y_5_pred = np.apply_along_axis(cls_5_to_value, 0, logRegL2_5_cls.predict(test_X))\n",
    "\n",
    "print('Train accuracy: ', logRegL2_5_cls.score(train_X, train_y_5_cls))\n",
    "print('Train MSE: ', mean_squared_error(train_y_5_pred, train_y_5_cls.apply(cls_5_to_value)))\n",
    "\n",
    "print('Valid accuracy: ', logRegL2_5_cls.score(val_X, val_y_5_cls))\n",
    "print('Valid MSE: ', mean_squared_error(val_y_5_pred, val_y_5_cls.apply(cls_5_to_value)))\n",
    "\n",
    "print('Test accuracy: ', logRegL2_5_cls.score(test_X, test_y_5_cls))\n",
    "print('Test MSE: ', mean_squared_error(test_y_5_pred, test_y_5_cls.apply(cls_5_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grigor/anaconda3/envs/work/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:760: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6566621191450659\n",
      "Train MSE:  0.8618311353645597\n",
      "Valid accuracy:  0.3734087694483734\n",
      "Valid MSE:  1.3454738330975955\n",
      "Test accuracy:  0.38613861386138615\n",
      "Test MSE:  1.3426449787835926\n"
     ]
    }
   ],
   "source": [
    "# Regularization c = 1/alpha = 0.1\n",
    "logRegL2_10_cls = LogisticRegression(penalty='l2', C = 0.1, solver='lbfgs',multi_class='multinomial').fit(train_X, train_y_10_cls)\n",
    "\n",
    "train_y_10_pred = np.apply_along_axis(cls_10_to_value, 0, logRegL2_10_cls.predict(train_X))\n",
    "val_y_10_pred = np.apply_along_axis(cls_10_to_value, 0, logRegL2_10_cls.predict(val_X))\n",
    "test_y_10_pred = np.apply_along_axis(cls_10_to_value, 0, logRegL2_10_cls.predict(test_X))\n",
    "\n",
    "print('Train accuracy: ', logRegL2_10_cls.score(train_X, train_y_10_cls))\n",
    "print('Train MSE: ', mean_squared_error(train_y_10_pred, train_y_10_cls.apply(cls_10_to_value)))\n",
    "\n",
    "print('Valid accuracy: ', logRegL2_10_cls.score(val_X, val_y_10_cls))\n",
    "print('Valid MSE: ', mean_squared_error(val_y_10_pred, val_y_10_cls.apply(cls_10_to_value)))\n",
    "\n",
    "print('Test accuracy: ', logRegL2_10_cls.score(test_X, test_y_10_cls))\n",
    "print('Test MSE: ', mean_squared_error(test_y_10_pred, test_y_10_cls.apply(cls_10_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grigor/anaconda3/envs/work/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:760: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.5842049416401395\n",
      "Train MSE:  0.806976656055783\n",
      "Valid accuracy:  0.20862800565770862\n",
      "Valid MSE:  1.2661775106082036\n",
      "Test accuracy:  0.20332390381895332\n",
      "Test MSE:  1.2583097595473833\n"
     ]
    }
   ],
   "source": [
    "# Regularization c = 1/alpha = 0.1\n",
    "logRegL2_20_cls = LogisticRegression(penalty='l2', C = 0.1, solver='lbfgs',multi_class='multinomial').fit(train_X, train_y_20_cls)\n",
    "\n",
    "train_y_20_pred = np.apply_along_axis(cls_20_to_value, 0, logRegL2_20_cls.predict(train_X))\n",
    "val_y_20_pred = np.apply_along_axis(cls_20_to_value, 0, logRegL2_20_cls.predict(val_X))\n",
    "test_y_20_pred = np.apply_along_axis(cls_20_to_value, 0, logRegL2_20_cls.predict(test_X))\n",
    "\n",
    "print('Train accuracy: ', logRegL2_20_cls.score(train_X, train_y_20_cls))\n",
    "print('Train MSE: ', mean_squared_error(train_y_20_pred, train_y_20_cls.apply(cls_20_to_value)))\n",
    "\n",
    "print('Valid accuracy: ', logRegL2_20_cls.score(val_X, val_y_20_cls))\n",
    "print('Valid MSE: ', mean_squared_error(val_y_20_pred, val_y_20_cls.apply(cls_20_to_value)))\n",
    "\n",
    "print('Test accuracy: ', logRegL2_20_cls.score(test_X, test_y_20_cls))\n",
    "print('Test MSE: ', mean_squared_error(test_y_20_pred, test_y_20_cls.apply(cls_20_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression vs Logistic Regression (without regularization)\n",
      "Test R^2\n",
      "Linear Reg: -5.173955098096975e+18\n",
      "Log Reg (5 cls): -0.18030078679410133\n",
      "Log Reg (10 cls): 0.023373888145752808\n",
      "Log Reg (20 cls): 0.0374326801652306\n",
      "Test Accuracy\n",
      "Linear Reg (5 cls): 0.5721357850070722\n",
      "Log Reg (5 cls): 0.5823903818953324\n",
      "Linear Reg (10 cls): 0.326025459688826\n",
      "Log Reg (10 cls): 0.3497171145685997\n",
      "Linear Reg (20 cls): 0.1637199434229137\n",
      "Log Reg (20 cls): 0.18705799151343705\n",
      "Test MSE\n",
      "Linear Reg: 7.717025537651409e+18\n",
      "Log Reg (5 cls): 2.0438472418670437\n",
      "Log Reg (10 cls): 1.5484441301272984\n",
      "Log Reg (20 cls): 1.458981612446959\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression vs Logistic Regression (without regularization)\")\n",
    "test_y_5_pred = np.apply_along_axis(cls_5_to_value, 0, logReg_5_cls.predict(test_X))\n",
    "test_y_10_pred = np.apply_along_axis(cls_10_to_value, 0, logReg_10_cls.predict(test_X))\n",
    "test_y_20_pred = np.apply_along_axis(cls_20_to_value, 0, logReg_20_cls.predict(test_X))\n",
    "\n",
    "print(\"Test R^2\")\n",
    "print(\"Linear Reg:\", reg.score(test_X, test_y))\n",
    "print(\"Log Reg (5 cls):\", r2_score(test_y, test_y_5_pred))\n",
    "print(\"Log Reg (10 cls):\", r2_score(test_y, test_y_10_pred))\n",
    "print(\"Log Reg (20 cls):\", r2_score(test_y, test_y_20_pred))\n",
    "\n",
    "print(\"Test Accuracy\")\n",
    "lin_y_5_cls = np.apply_along_axis(to_5_classes, 0, reg.predict(test_X))\n",
    "lin_y_10_cls = np.apply_along_axis(to_10_classes, 0, reg.predict(test_X))\n",
    "lin_y_20_cls = np.apply_along_axis(to_20_classes, 0, reg.predict(test_X))\n",
    "print(\"Linear Reg (5 cls):\", accuracy_score(test_y_5_cls, lin_y_5_cls))\n",
    "print(\"Log Reg (5 cls):\", logReg_5_cls.score(test_X, test_y_5_cls))\n",
    "print(\"Linear Reg (10 cls):\", accuracy_score(test_y_10_cls, lin_y_10_cls))\n",
    "print(\"Log Reg (10 cls):\", logReg_10_cls.score(test_X, test_y_10_cls))\n",
    "print(\"Linear Reg (20 cls):\", accuracy_score(test_y_20_cls, lin_y_20_cls))\n",
    "print(\"Log Reg (20 cls):\", logReg_20_cls.score(test_X, test_y_20_cls))\n",
    "\n",
    "print(\"Test MSE\")\n",
    "print(\"Linear Reg:\", mean_squared_error(reg.predict(test_X), test_y))\n",
    "print(\"Log Reg (5 cls):\", mean_squared_error(test_y_5_pred, test_y_5_cls.apply(cls_5_to_value)))\n",
    "print(\"Log Reg (10 cls):\", mean_squared_error(test_y_10_pred, test_y_10_cls.apply(cls_10_to_value)))\n",
    "print(\"Log Reg (20 cls):\", mean_squared_error(test_y_20_pred, test_y_20_cls.apply(cls_20_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression vs Logistic Regression (with l2 regularization)\n",
      "Test R^2\n",
      "Ridge Reg: 0.34131220992775924\n",
      "Log Reg L2 (5 cls): 0.05839047467655989\n",
      "Log Reg L2 (10 cls): 0.1763847544083318\n",
      "Log Reg L2 (20 cls): 0.18171903468553674\n",
      "Test Accuracy\n",
      "Ridge Reg (5 cls): 0.6294200848656294\n",
      "Log Reg L2 (5 cls): 0.632956152758133\n",
      "Ridge Reg (10 cls): 0.38189533239038187\n",
      "Log Reg L2 (10 cls): 0.38613861386138615\n",
      "Ridge Reg (20 cls): 0.20226308345120225\n",
      "Log Reg L2 (20 cls): 0.20332390381895332\n",
      "Test MSE\n",
      "Ridge Reg: 0.9824419425665801\n",
      "Log Reg L2 (5 cls): 1.7001414427157002\n",
      "Log Reg L2 (10 cls): 1.3426449787835926\n",
      "Log Reg L2 (20 cls): 1.2583097595473833\n"
     ]
    }
   ],
   "source": [
    "print(\"Ridge Regression vs Logistic Regression (with l2 regularization)\")\n",
    "test_y_5_pred = np.apply_along_axis(cls_5_to_value, 0, logRegL2_5_cls.predict(test_X))\n",
    "test_y_10_pred = np.apply_along_axis(cls_10_to_value, 0, logRegL2_10_cls.predict(test_X))\n",
    "test_y_20_pred = np.apply_along_axis(cls_20_to_value, 0, logRegL2_20_cls.predict(test_X))\n",
    "\n",
    "print(\"Test R^2\")\n",
    "print(\"Ridge Reg:\", ridgeReg.score(test_X, test_y))\n",
    "print(\"Log Reg L2 (5 cls):\", r2_score(test_y, test_y_5_pred))\n",
    "print(\"Log Reg L2 (10 cls):\", r2_score(test_y, test_y_10_pred))\n",
    "print(\"Log Reg L2 (20 cls):\", r2_score(test_y, test_y_20_pred))\n",
    "\n",
    "print(\"Test Accuracy\")\n",
    "lin_y_5_cls = np.apply_along_axis(to_5_classes, 0, ridgeReg.predict(test_X))\n",
    "lin_y_10_cls = np.apply_along_axis(to_10_classes, 0, ridgeReg.predict(test_X))\n",
    "lin_y_20_cls = np.apply_along_axis(to_20_classes, 0, ridgeReg.predict(test_X))\n",
    "print(\"Ridge Reg (5 cls):\", accuracy_score(test_y_5_cls, lin_y_5_cls))\n",
    "print(\"Log Reg L2 (5 cls):\", logRegL2_5_cls.score(test_X, test_y_5_cls))\n",
    "print(\"Ridge Reg (10 cls):\", accuracy_score(test_y_10_cls, lin_y_10_cls))\n",
    "print(\"Log Reg L2 (10 cls):\", logRegL2_10_cls.score(test_X, test_y_10_cls))\n",
    "print(\"Ridge Reg (20 cls):\", accuracy_score(test_y_20_cls, lin_y_20_cls))\n",
    "print(\"Log Reg L2 (20 cls):\", logRegL2_20_cls.score(test_X, test_y_20_cls))\n",
    "\n",
    "print(\"Test MSE\")\n",
    "print(\"Ridge Reg:\", mean_squared_error(ridgeReg.predict(test_X), test_y))\n",
    "print(\"Log Reg L2 (5 cls):\", mean_squared_error(test_y_5_pred, test_y_5_cls.apply(cls_5_to_value)))\n",
    "print(\"Log Reg L2 (10 cls):\", mean_squared_error(test_y_10_pred, test_y_10_cls.apply(cls_10_to_value)))\n",
    "print(\"Log Reg L2 (20 cls):\", mean_squared_error(test_y_20_pred, test_y_20_cls.apply(cls_20_to_value)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree & Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2:  0.4285439428914224\n",
      "Train MSE:  0.8440804787948721\n",
      "Valid R^2:  0.345017075863551\n",
      "Valid MSE:  0.9339722991508874\n",
      "Test R^2:  0.3863013694194297\n",
      "Test MSE:  0.9153399893930031\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtreg = DecisionTreeRegressor(random_state = 0, max_depth = 8)\n",
    "dtreg.fit(train_X, train_y)\n",
    "\n",
    "print('Train R^2: ', dtreg.score(train_X, train_y))\n",
    "print('Train MSE: ', mean_squared_error(dtreg.predict(train_X), train_y))\n",
    "\n",
    "print('Valid R^2: ', dtreg.score(val_X, val_y))\n",
    "print('Valid MSE: ', mean_squared_error(dtreg.predict(val_X), val_y))\n",
    "\n",
    "print('Test R^2: ', dtreg.score(test_X, test_y))\n",
    "print('Test MSE: ', mean_squared_error(dtreg.predict(test_X), test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2:  0.8277948699701526\n",
      "Train MSE:  0.25435899540900153\n",
      "Valid R^2:  0.39379083619592503\n",
      "Valid MSE:  0.8644234003976554\n",
      "Test R^2:  0.44413131717729437\n",
      "Test MSE:  0.8290858230488398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfreg = RandomForestRegressor(max_depth=32, random_state=0,n_estimators=100)\n",
    "rfreg.fit(train_X, train_y)\n",
    "\n",
    "print('Train R^2: ', rfreg.score(train_X, train_y))\n",
    "print('Train MSE: ', mean_squared_error(rfreg.predict(train_X), train_y))\n",
    "\n",
    "print('Valid R^2: ', rfreg.score(val_X, val_y))\n",
    "print('Valid MSE: ', mean_squared_error(rfreg.predict(val_X), val_y))\n",
    "\n",
    "print('Test R^2: ', rfreg.score(test_X, test_y))\n",
    "print('Test MSE: ', mean_squared_error(rfreg.predict(test_X), test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.682355616189177\n",
      "Train MSE:  1.4391390025769288\n",
      "Valid Accuracy:  0.6467468175388967\n",
      "Valid MSE:  1.5233380480905234\n",
      "Test Accuracy:  0.6538189533239038\n",
      "Test MSE:  1.5205091937765205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# decision tree 5 classess\n",
    "dt_5_cls = DecisionTreeClassifier(random_state = 0, max_depth = 8).fit(train_X, train_y_5_cls)\n",
    "\n",
    "print('Train Accuracy: ', dt_5_cls.score(train_X, train_y_5_cls))\n",
    "print('Train MSE: ', mean_squared_error(np.apply_along_axis(cls_5_to_value, 0, dt_5_cls.predict(train_X)), train_y_5_cls.apply(cls_5_to_value)))\n",
    "\n",
    "print('Valid Accuracy: ', dt_5_cls.score(val_X, val_y_5_cls))\n",
    "print('Valid MSE: ', mean_squared_error(np.apply_along_axis(cls_5_to_value, 0, dt_5_cls.predict(val_X)), val_y_5_cls.apply(cls_5_to_value)))\n",
    "\n",
    "print('Test Accuracy: ', dt_5_cls.score(test_X, test_y_5_cls))\n",
    "print('Test MSE: ', mean_squared_error(np.apply_along_axis(cls_5_to_value, 0, dt_5_cls.predict(test_X)), test_y_5_cls.apply(cls_5_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.4653630438077914\n",
      "Train MSE:  1.0494164013945733\n",
      "Valid Accuracy:  0.4169024045261669\n",
      "Valid MSE:  1.1014851485148516\n",
      "Test Accuracy:  0.423974540311174\n",
      "Test MSE:  1.0466760961810466\n"
     ]
    }
   ],
   "source": [
    "# decision tree 10 classess\n",
    "dt_10_cls = DecisionTreeClassifier(random_state = 0, max_depth = 8).fit(train_X, train_y_10_cls)\n",
    "\n",
    "print('Train Accuracy: ', dt_10_cls.score(train_X, train_y_10_cls))\n",
    "print('Train MSE: ', mean_squared_error(np.apply_along_axis(cls_10_to_value, 0, dt_10_cls.predict(train_X)), train_y_10_cls.apply(cls_10_to_value)))\n",
    "\n",
    "print('Valid Accuracy: ', dt_10_cls.score(val_X, val_y_10_cls))\n",
    "print('Valid MSE: ', mean_squared_error(np.apply_along_axis(cls_10_to_value, 0, dt_10_cls.predict(val_X)), val_y_10_cls.apply(cls_10_to_value)))\n",
    "\n",
    "print('Test Accuracy: ', dt_10_cls.score(test_X, test_y_10_cls))\n",
    "print('Test MSE: ', mean_squared_error(np.apply_along_axis(cls_10_to_value, 0, dt_10_cls.predict(test_X)), test_y_10_cls.apply(cls_10_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.2788388661512809\n",
      "Train MSE:  1.0224533879035926\n",
      "Valid Accuracy:  0.22595473833097596\n",
      "Valid MSE:  1.0235148514851484\n",
      "Test Accuracy:  0.2256011315417256\n",
      "Test MSE:  1.0346534653465347\n"
     ]
    }
   ],
   "source": [
    "# decision tree 20 classess\n",
    "dt_20_cls = DecisionTreeClassifier(random_state = 0, max_depth = 8).fit(train_X, train_y_20_cls)\n",
    "\n",
    "print('Train Accuracy: ', dt_20_cls.score(train_X, train_y_20_cls))\n",
    "print('Train MSE: ', mean_squared_error(np.apply_along_axis(cls_20_to_value, 0, dt_20_cls.predict(train_X)), train_y_20_cls.apply(cls_20_to_value)))\n",
    "\n",
    "print('Valid Accuracy: ', dt_20_cls.score(val_X, val_y_20_cls))\n",
    "print('Valid MSE: ', mean_squared_error(np.apply_along_axis(cls_20_to_value, 0, dt_20_cls.predict(val_X)), val_y_20_cls.apply(cls_20_to_value)))\n",
    "\n",
    "print('Test Accuracy: ', dt_20_cls.score(test_X, test_y_20_cls))\n",
    "print('Test MSE: ', mean_squared_error(np.apply_along_axis(cls_20_to_value, 0, dt_20_cls.predict(test_X)), test_y_20_cls.apply(cls_20_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.807340974384335\n",
      "Train MSE:  0.34129916233225344\n",
      "Valid Accuracy:  0.2950526704558547\n",
      "Valid MSE:  1.2123397734570602\n",
      "Test Accuracy:  0.36139665309725555\n",
      "Test MSE:  1.1348940652603077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# random forest 5 classess\n",
    "rf_5_cls = RandomForestRegressor(max_depth=32, random_state=0,n_estimators=100).fit(train_X, train_y_5_cls)\n",
    "\n",
    "print('Train Accuracy: ', rf_5_cls.score(train_X, train_y_5_cls))\n",
    "print('Train MSE: ', mean_squared_error(np.apply_along_axis(cls_5_to_value, 0, rf_5_cls.predict(train_X)), train_y_5_cls.apply(cls_5_to_value)))\n",
    "\n",
    "print('Valid Accuracy: ', rf_5_cls.score(val_X, val_y_5_cls))\n",
    "print('Valid MSE: ', mean_squared_error(np.apply_along_axis(cls_5_to_value, 0, rf_5_cls.predict(val_X)), val_y_5_cls.apply(cls_5_to_value)))\n",
    "\n",
    "print('Test Accuracy: ', rf_5_cls.score(test_X, test_y_5_cls))\n",
    "print('Test MSE: ', mean_squared_error(np.apply_along_axis(cls_5_to_value, 0, rf_5_cls.predict(test_X)), test_y_5_cls.apply(cls_5_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.8357200285743208\n",
      "Train MSE:  0.2572622672975503\n",
      "Valid Accuracy:  0.3739665811060906\n",
      "Valid MSE:  0.9502188073078852\n",
      "Test Accuracy:  0.41943151152941704\n",
      "Test MSE:  0.9218411010570399\n"
     ]
    }
   ],
   "source": [
    "#random forest with 10 classes\n",
    "rf_10_cls = RandomForestRegressor(max_depth=32, random_state=0,n_estimators=100).fit(train_X, train_y_10_cls)\n",
    "\n",
    "print('Train Accuracy: ', rf_10_cls.score(train_X, train_y_10_cls))\n",
    "print('Train MSE: ', mean_squared_error(np.apply_along_axis(cls_10_to_value, 0, rf_10_cls.predict(train_X)), train_y_10_cls.apply(cls_10_to_value)))\n",
    "\n",
    "print('Valid Accuracy: ', rf_10_cls.score(val_X, val_y_10_cls))\n",
    "print('Valid MSE: ', mean_squared_error(np.apply_along_axis(cls_10_to_value, 0, rf_10_cls.predict(val_X)), val_y_10_cls.apply(cls_10_to_value)))\n",
    "\n",
    "print('Test Accuracy: ', rf_10_cls.score(test_X, test_y_10_cls))\n",
    "print('Test MSE: ', mean_squared_error(np.apply_along_axis(cls_10_to_value, 0, rf_10_cls.predict(test_X)), test_y_10_cls.apply(cls_10_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.6412691646069492\n",
      "Train MSE:  0.5370981301891746\n",
      "Valid Accuracy:  0.3895101761621004\n",
      "Valid MSE:  0.8834431021446513\n",
      "Test Accuracy:  0.43320073004051596\n",
      "Test MSE:  0.8558925643931317\n"
     ]
    }
   ],
   "source": [
    "# random forest 20 classess\n",
    "rf_20_cls = RandomForestRegressor(max_depth=16, random_state=0,n_estimators=100).fit(train_X, train_y_20_cls)\n",
    "\n",
    "print('Train Accuracy: ', rf_20_cls.score(train_X, train_y_20_cls))\n",
    "print('Train MSE: ', mean_squared_error(np.apply_along_axis(cls_20_to_value, 0, rf_20_cls.predict(train_X)), train_y_20_cls.apply(cls_20_to_value)))\n",
    "\n",
    "print('Valid Accuracy: ', rf_20_cls.score(val_X, val_y_20_cls))\n",
    "print('Valid MSE: ', mean_squared_error(np.apply_along_axis(cls_20_to_value, 0, rf_20_cls.predict(val_X)), val_y_20_cls.apply(cls_20_to_value)))\n",
    "\n",
    "print('Test Accuracy: ', rf_20_cls.score(test_X, test_y_20_cls))\n",
    "print('Test MSE: ', mean_squared_error(np.apply_along_axis(cls_20_to_value, 0, rf_20_cls.predict(test_X)), test_y_20_cls.apply(cls_20_to_value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression vs classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R^2\n",
      "Reg: 0.3863013694194297\n",
      "Cls (5 cls): 0.18043880741900764\n",
      "Cls (10 cls): 0.35694421481363126\n",
      "Cls (20 cls): 0.32453549864056874\n",
      "Test Accuracy\n",
      "Reg (5 cls): 0.6534653465346535\n",
      "Cls (5 cls): 0.6538189533239038\n",
      "Reg (10 cls): 0.41937765205091937\n",
      "Cls (10 cls): 0.423974540311174\n",
      "Reg (20 cls): 0.22277227722772278\n",
      "Cls (20 cls): 0.2256011315417256\n",
      "Test MSE\n",
      "Reg: 0.9153399893930031\n",
      "Cls (5 cls): 1.5205091937765205\n",
      "Cls (10 cls): 1.0466760961810466\n",
      "Cls (20 cls): 1.0346534653465347\n"
     ]
    }
   ],
   "source": [
    "test_y_5_pred = np.apply_along_axis(cls_5_to_value, 0, dt_5_cls.predict(test_X))\n",
    "test_y_10_pred = np.apply_along_axis(cls_10_to_value, 0, dt_10_cls.predict(test_X))\n",
    "test_y_20_pred = np.apply_along_axis(cls_20_to_value, 0, dt_20_cls.predict(test_X))\n",
    "\n",
    "print(\"Test R^2\")\n",
    "print(\"Reg:\", dtreg.score(test_X, test_y))\n",
    "print(\"Cls (5 cls):\", r2_score(test_y, test_y_5_pred))\n",
    "print(\"Cls (10 cls):\", r2_score(test_y, test_y_10_pred))\n",
    "print(\"Cls (20 cls):\", r2_score(test_y, test_y_20_pred))\n",
    "\n",
    "print(\"Test Accuracy\")\n",
    "dt_y_5_cls = np.apply_along_axis(to_5_classes, 0, dtreg.predict(test_X))\n",
    "dt_y_10_cls = np.apply_along_axis(to_10_classes, 0, dtreg.predict(test_X))\n",
    "dt_y_20_cls = np.apply_along_axis(to_20_classes, 0, dtreg.predict(test_X))\n",
    "print(\"Reg (5 cls):\", accuracy_score(test_y_5_cls, dt_y_5_cls))\n",
    "print(\"Cls (5 cls):\", dt_5_cls.score(test_X, test_y_5_cls))\n",
    "print(\"Reg (10 cls):\", accuracy_score(test_y_10_cls, dt_y_10_cls))\n",
    "print(\"Cls (10 cls):\", dt_10_cls.score(test_X, test_y_10_cls))\n",
    "print(\"Reg (20 cls):\", accuracy_score(test_y_20_cls, dt_y_20_cls))\n",
    "print(\"Cls (20 cls):\", dt_20_cls.score(test_X, test_y_20_cls))\n",
    "\n",
    "print(\"Test MSE\")\n",
    "print(\"Reg:\", mean_squared_error(dtreg.predict(test_X), test_y))\n",
    "print(\"Cls (5 cls):\", mean_squared_error(test_y_5_pred, test_y_5_cls.apply(cls_5_to_value)))\n",
    "print(\"Cls (10 cls):\", mean_squared_error(test_y_10_pred, test_y_10_cls.apply(cls_10_to_value)))\n",
    "print(\"Cls (20 cls):\", mean_squared_error(test_y_20_pred, test_y_20_cls.apply(cls_20_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression vs Random Forest Classification\n",
      "Test R^2\n",
      "Reg: 0.44413131717729437\n",
      "Cls (5 cls): 0.4326914561301335\n",
      "Cls (10 cls): 0.43817476475853623\n",
      "Cls (20 cls): 0.4407802807085459\n",
      "Test Accuracy\n",
      "Reg (5 cls): 0.6630127298444131\n",
      "Cls (5 cls): 0.36139665309725555\n",
      "Reg (10 cls): 0.4282178217821782\n",
      "Cls (10 cls): 0.41943151152941704\n",
      "Reg (20 cls): 0.2362093352192362\n",
      "Cls (20 cls): 0.43320073004051596\n",
      "Test MSE\n",
      "Reg: 0.8290858230488398\n",
      "Cls (5 cls): 0.8461485339101295\n",
      "Cls (10 cls): 0.8379701033064753\n",
      "Cls (20 cls): 0.8340839402563981\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Regression vs Random Forest Classification\")\n",
    "test_y_5_pred = np.apply_along_axis(cls_5_to_value, 0, rf_5_cls.predict(test_X))\n",
    "test_y_10_pred = np.apply_along_axis(cls_10_to_value, 0, rf_10_cls.predict(test_X))\n",
    "test_y_20_pred = np.apply_along_axis(cls_20_to_value, 0, rf_20_cls.predict(test_X))\n",
    "\n",
    "print(\"Test R^2\")\n",
    "print(\"Reg:\", rfreg.score(test_X, test_y))\n",
    "print(\"Cls (5 cls):\", r2_score(test_y, test_y_5_pred))\n",
    "print(\"Cls (10 cls):\", r2_score(test_y, test_y_10_pred))\n",
    "print(\"Cls (20 cls):\", r2_score(test_y, test_y_20_pred))\n",
    "\n",
    "print(\"Test Accuracy\")\n",
    "rf_y_5_cls = np.apply_along_axis(to_5_classes, 0, rfreg.predict(test_X))\n",
    "rf_y_10_cls = np.apply_along_axis(to_10_classes, 0, rfreg.predict(test_X))\n",
    "rf_y_20_cls = np.apply_along_axis(to_20_classes, 0, rfreg.predict(test_X))\n",
    "print(\"Reg (5 cls):\", accuracy_score(test_y_5_cls, rf_y_5_cls))\n",
    "print(\"Cls (5 cls):\", rf_5_cls.score(test_X, test_y_5_cls))\n",
    "print(\"Reg (10 cls):\", accuracy_score(test_y_10_cls, rf_y_10_cls))\n",
    "print(\"Cls (10 cls):\", rf_10_cls.score(test_X, test_y_10_cls))\n",
    "print(\"Reg (20 cls):\", accuracy_score(test_y_20_cls, rf_y_20_cls))\n",
    "print(\"Cls (20 cls):\", rf_20_cls.score(test_X, test_y_20_cls))\n",
    "\n",
    "print(\"Test MSE\")\n",
    "print(\"Reg:\", mean_squared_error(rfreg.predict(test_X), test_y))\n",
    "# print(\"Cls (5 cls):\", mean_squared_error(test_y_5_pred, test_y_5_cls.apply(cls_5_to_value)))\n",
    "# print(\"Cls (10 cls):\", mean_squared_error(test_y_10_pred, test_y_10_cls.apply(cls_10_to_value)))\n",
    "# print(\"Cls (20 cls):\", mean_squared_error(test_y_20_pred, test_y_20_cls.apply(cls_20_to_value)))\n",
    "print(\"Cls (5 cls):\", mean_squared_error(test_y_5_pred, test_y))\n",
    "print(\"Cls (10 cls):\", mean_squared_error(test_y_10_pred, test_y))\n",
    "print(\"Cls (20 cls):\", mean_squared_error(test_y_20_pred, test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['runtime', 'documentary', 'drama', 'horror', 'action', 'animation',\n",
      "       'hue_sd', 'saturation_sd ', 'hue', 'saturation'],\n",
      "      dtype='object')\n",
      "[0.12409527 0.11660363 0.07672377 0.07490631 0.02208307 0.01840106\n",
      " 0.01460248 0.01437474 0.01323208 0.01302269]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances_order = np.argsort(rfreg.feature_importances_)[::-1]\n",
    "print(train_X.columns[importances_order[:10]])\n",
    "print(rfreg.feature_importances_[importances_order[:10]])\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.barh(range(10),rfreg.feature_importances_[importances_order[:10]])\n",
    "plt.yticks(range(10), train_X.columns[importances_order[:10]], rotation='horizontal')\n",
    "plt.savefig('../plots/feature_importancvce.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2:  0.6506230970382416\n",
      "Train MSE:  0.5160540690109419\n",
      "Valid R^2:  0.38669584852279837\n",
      "Valid MSE:  0.8745404915542743\n",
      "Test R^2:  0.4384435177634063\n",
      "Test MSE:  0.8375692544852968\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgreg = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "xgreg.fit(train_X, train_y)\n",
    "\n",
    "print('Train R^2: ', xgreg.score(train_X, train_y))\n",
    "print('Train MSE: ', mean_squared_error(xgreg.predict(train_X), train_y))\n",
    "\n",
    "print('Valid R^2: ', xgreg.score(val_X, val_y))\n",
    "print('Valid MSE: ', mean_squared_error(xgreg.predict(val_X), val_y))\n",
    "\n",
    "print('Test R^2: ', xgreg.score(test_X, test_y))\n",
    "print('Test MSE: ', mean_squared_error(xgreg.predict(test_X), test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.8343944217068364\n",
      "Train MSE:  0.7315446415037138\n",
      "Valid Accuracy:  0.6403818953323904\n",
      "Valid MSE:  1.5855728429985856\n",
      "Test Accuracy:  0.6584158415841584\n",
      "Test MSE:  1.502121640735502\n"
     ]
    }
   ],
   "source": [
    "# XGBoost 5 classes\n",
    "xgb_5_cls = xgb.XGBClassifier(objective ='multi:softmax').fit(train_X, train_y_5_cls)\n",
    "\n",
    "print('Train Accuracy: ', xgb_5_cls.score(train_X, train_y_5_cls))\n",
    "print('Train MSE: ', mean_squared_error(np.apply_along_axis(cls_5_to_value, 0, xgb_5_cls.predict(train_X)), train_y_5_cls.apply(cls_5_to_value)))\n",
    "\n",
    "print('Valid Accuracy: ', xgb_5_cls.score(val_X, val_y_5_cls))\n",
    "print('Valid MSE: ', mean_squared_error(np.apply_along_axis(cls_5_to_value, 0, xgb_5_cls.predict(val_X)), val_y_5_cls.apply(cls_5_to_value)))\n",
    "\n",
    "print('Test Accuracy: ', xgb_5_cls.score(test_X, test_y_5_cls))\n",
    "print('Test MSE: ', mean_squared_error(np.apply_along_axis(cls_5_to_value, 0, xgb_5_cls.predict(test_X)), test_y_5_cls.apply(cls_5_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.7816431711383962\n",
      "Train MSE:  0.4185235713202971\n",
      "Valid Accuracy:  0.413012729844413\n",
      "Valid MSE:  1.1739745403111739\n",
      "Test Accuracy:  0.41336633663366334\n",
      "Test MSE:  1.1488684582743989\n"
     ]
    }
   ],
   "source": [
    "# XGBoost 10 classes\n",
    "xgb_10_cls = xgb.XGBClassifier(objective ='multi:softmax').fit(train_X, train_y_10_cls)\n",
    "\n",
    "print('Train Accuracy: ', xgb_10_cls.score(train_X, train_y_10_cls))\n",
    "print('Train MSE: ', mean_squared_error(np.apply_along_axis(cls_10_to_value, 0, xgb_10_cls.predict(train_X)), train_y_10_cls.apply(cls_10_to_value)))\n",
    "\n",
    "print('Valid Accuracy: ', xgb_10_cls.score(val_X, val_y_10_cls))\n",
    "print('Valid MSE: ', mean_squared_error(np.apply_along_axis(cls_10_to_value, 0, xgb_10_cls.predict(val_X)), val_y_10_cls.apply(cls_10_to_value)))\n",
    "\n",
    "print('Test Accuracy: ', xgb_10_cls.score(test_X, test_y_10_cls))\n",
    "print('Test MSE: ', mean_squared_error(np.apply_along_axis(cls_10_to_value, 0, xgb_10_cls.predict(test_X)), test_y_10_cls.apply(cls_10_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.8081703804759739\n",
      "Train MSE:  0.24238290131878126\n",
      "Valid Accuracy:  0.22065063649222066\n",
      "Valid MSE:  1.134016973125884\n",
      "Test Accuracy:  0.22772277227722773\n",
      "Test MSE:  1.091495756718529\n"
     ]
    }
   ],
   "source": [
    "# XGBoost 20 classes\n",
    "xgb_20_cls = xgb.XGBClassifier(objective ='multi:softmax').fit(train_X, train_y_20_cls)\n",
    "\n",
    "print('Train Accuracy: ', xgb_20_cls.score(train_X, train_y_20_cls))\n",
    "print('Train MSE: ', mean_squared_error(np.apply_along_axis(cls_20_to_value, 0, xgb_20_cls.predict(train_X)), train_y_20_cls.apply(cls_20_to_value)))\n",
    "\n",
    "print('Valid Accuracy: ', xgb_20_cls.score(val_X, val_y_20_cls))\n",
    "print('Valid MSE: ', mean_squared_error(np.apply_along_axis(cls_20_to_value, 0, xgb_20_cls.predict(val_X)), val_y_20_cls.apply(cls_20_to_value)))\n",
    "\n",
    "print('Test Accuracy: ', xgb_20_cls.score(test_X, test_y_20_cls))\n",
    "print('Test MSE: ', mean_squared_error(np.apply_along_axis(cls_20_to_value, 0, xgb_20_cls.predict(test_X)), test_y_20_cls.apply(cls_20_to_value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regression vs XGBoost Classification\n",
      "Test R^2\n",
      "Reg: 0.4384435177634063\n",
      "Cls (5 cls): 0.19343074338304445\n",
      "Cls (10 cls): 0.2970580282348778\n",
      "Cls (20 cls): 0.2937863363315256\n",
      "Test Accuracy\n",
      "Reg (5 cls): 0.6697312588401697\n",
      "Cls (5 cls): 0.6584158415841584\n",
      "Reg (10 cls): 0.43316831683168316\n",
      "Cls (10 cls): 0.41336633663366334\n",
      "Reg (20 cls): 0.22984441301272984\n",
      "Cls (20 cls): 0.22772277227722773\n",
      "Test MSE\n",
      "Reg: 0.8375692544852968\n",
      "Cls (5 cls): 1.502121640735502\n",
      "Cls (10 cls): 1.1488684582743989\n",
      "Cls (20 cls): 1.091495756718529\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBoost Regression vs XGBoost Classification\")\n",
    "test_y_5_pred = np.apply_along_axis(cls_5_to_value, 0, xgb_5_cls.predict(test_X))\n",
    "test_y_10_pred = np.apply_along_axis(cls_10_to_value, 0, xgb_10_cls.predict(test_X))\n",
    "test_y_20_pred = np.apply_along_axis(cls_20_to_value, 0, xgb_20_cls.predict(test_X))\n",
    "\n",
    "print(\"Test R^2\")\n",
    "print(\"Reg:\", xgreg.score(test_X, test_y))\n",
    "print(\"Cls (5 cls):\", r2_score(test_y, test_y_5_pred))\n",
    "print(\"Cls (10 cls):\", r2_score(test_y, test_y_10_pred))\n",
    "print(\"Cls (20 cls):\", r2_score(test_y, test_y_20_pred))\n",
    "\n",
    "print(\"Test Accuracy\")\n",
    "xg_y_5_cls = np.apply_along_axis(to_5_classes, 0, xgreg.predict(test_X))\n",
    "xg_y_10_cls = np.apply_along_axis(to_10_classes, 0, xgreg.predict(test_X))\n",
    "xg_y_20_cls = np.apply_along_axis(to_20_classes, 0, xgreg.predict(test_X))\n",
    "print(\"Reg (5 cls):\", accuracy_score(test_y_5_cls, xg_y_5_cls))\n",
    "print(\"Cls (5 cls):\", xgb_5_cls.score(test_X, test_y_5_cls))\n",
    "print(\"Reg (10 cls):\", accuracy_score(test_y_10_cls, xg_y_10_cls))\n",
    "print(\"Cls (10 cls):\", xgb_10_cls.score(test_X, test_y_10_cls))\n",
    "print(\"Reg (20 cls):\", accuracy_score(test_y_20_cls, xg_y_20_cls))\n",
    "print(\"Cls (20 cls):\", xgb_20_cls.score(test_X, test_y_20_cls))\n",
    "\n",
    "print(\"Test MSE\")\n",
    "print(\"Reg:\", mean_squared_error(xgreg.predict(test_X), test_y))\n",
    "print(\"Cls (5 cls):\", mean_squared_error(test_y_5_pred, test_y_5_cls.apply(cls_5_to_value)))\n",
    "print(\"Cls (10 cls):\", mean_squared_error(test_y_10_pred, test_y_10_cls.apply(cls_10_to_value)))\n",
    "print(\"Cls (20 cls):\", mean_squared_error(test_y_20_pred, test_y_20_cls.apply(cls_20_to_value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2:  0.6117073347182355\n",
      "Train MSE:  0.5735353659245503\n",
      "Valid R^2:  0.34876421444251493\n",
      "Valid MSE:  0.9286290703355009\n",
      "Test R^2:  0.3768354104581578\n",
      "Test MSE:  0.9294585980120388\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR(gamma='scale', C=1.0, epsilon=0.2)\n",
    "svr.fit(train_X, train_y)\n",
    "\n",
    "print('Train R^2: ', svr.score(train_X, train_y))\n",
    "print('Train MSE: ', mean_squared_error(svr.predict(train_X), train_y))\n",
    "\n",
    "print('Valid R^2: ', svr.score(val_X, val_y))\n",
    "print('Valid MSE: ', mean_squared_error(svr.predict(val_X), val_y))\n",
    "\n",
    "print('Test R^2: ', svr.score(test_X, test_y))\n",
    "print('Test MSE: ', mean_squared_error(svr.predict(test_X), test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.7683795664696074\n",
      "Train MSE:  1.147491283916932\n",
      "Valid Accuracy:  0.6223479490806223\n",
      "Valid MSE:  1.7043847241867043\n",
      "Test Accuracy:  0.6474540311173974\n",
      "Test MSE:  1.6364922206506365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_5_cls = SVC(gamma='scale', C=1.0).fit(train_X, train_y_5_cls)\n",
    "\n",
    "print('Train Accuracy: ', svc_5_cls.score(train_X, train_y_5_cls))\n",
    "print('Train MSE: ', mean_squared_error(np.apply_along_axis(cls_5_to_value, 0, svc_5_cls.predict(train_X)), train_y_5_cls.apply(cls_5_to_value)))\n",
    "\n",
    "print('Valid Accuracy: ', svc_5_cls.score(val_X, val_y_5_cls))\n",
    "print('Valid MSE: ', mean_squared_error(np.apply_along_axis(cls_5_to_value, 0, svc_5_cls.predict(val_X)), val_y_5_cls.apply(cls_5_to_value)))\n",
    "\n",
    "print('Test Accuracy: ', svc_5_cls.score(test_X, test_y_5_cls))\n",
    "print('Test MSE: ', mean_squared_error(np.apply_along_axis(cls_5_to_value, 0, svc_5_cls.predict(test_X)), test_y_5_cls.apply(cls_5_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_10_cls = SVC(gamma='scale', C=1.0).fit(train_X, train_y_10_cls)\n",
    "\n",
    "print('Train Accuracy: ', svc_10_cls.score(train_X, train_y_10_cls))\n",
    "print('Train MSE: ', mean_squared_error(np.apply_along_axis(cls_10_to_value, 0, svc_10_cls.predict(train_X)), train_y_10_cls.apply(cls_10_to_value)))\n",
    "\n",
    "print('Valid Accuracy: ', svc_10_cls.score(val_X, val_y_10_cls))\n",
    "print('Valid MSE: ', mean_squared_error(np.apply_along_axis(cls_10_to_value, 0, svc_10_cls.predict(val_X)), val_y_10_cls.apply(cls_10_to_value)))\n",
    "\n",
    "print('Test Accuracy: ', svc_10_cls.score(test_X, test_y_10_cls))\n",
    "print('Test MSE: ', mean_squared_error(np.apply_along_axis(cls_10_to_value, 0, svc_10_cls.predict(test_X)), test_y_10_cls.apply(cls_10_to_value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Accuracy:  0.5760194027588298\n",
    "Train MSE:  1.0870092466272547\n",
    "Valid Accuracy:  0.39816124469589814\n",
    "Valid MSE:  1.2577793493635079\n",
    "Test Accuracy:  0.4055869872701556\n",
    "Test MSE:  1.3125884016973126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Regression vs Classification\n",
      "Test R^2\n",
      "Reg: 0.3768354104581578\n",
      "Cls (5 cls): 0.10969439698709926\n",
      "Test Accuracy\n",
      "Reg (5 cls): 0.655940594059406\n",
      "Cls (5 cls): 0.6474540311173974\n",
      "Test MSE\n",
      "Reg: 0.9294585980120388\n",
      "Cls (5 cls): 1.6364922206506365\n"
     ]
    }
   ],
   "source": [
    "print(\"Support Vector Machine Regression vs Classification\")\n",
    "test_y_5_pred = np.apply_along_axis(cls_5_to_value, 0, svc_5_cls.predict(test_X))\n",
    "#test_y_10_pred = np.apply_along_axis(cls_10_to_value, 0, svc_10_cls.predict(test_X))\n",
    "#test_y_20_pred = np.apply_along_axis(cls_20_to_value, 0, svc_20_cls.predict(test_X))\n",
    "\n",
    "print(\"Test R^2\")\n",
    "print(\"Reg:\", svr.score(test_X, test_y))\n",
    "print(\"Cls (5 cls):\", r2_score(test_y, test_y_5_pred))\n",
    "#print(\"Cls (10 cls):\", r2_score(test_y, test_y_10_pred))\n",
    "#print(\"Cls (20 cls):\", r2_score(test_y, test_y_20_pred))\n",
    "\n",
    "print(\"Test Accuracy\")\n",
    "svr_y_5_cls = np.apply_along_axis(to_5_classes, 0, svr.predict(test_X))\n",
    "#svr_y_10_cls = np.apply_along_axis(to_10_classes, 0, svr.predict(test_X))\n",
    "#svr_y_20_cls = np.apply_along_axis(to_20_classes, 0, svr.predict(test_X))\n",
    "print(\"Reg (5 cls):\", accuracy_score(test_y_5_cls, svr_y_5_cls))\n",
    "print(\"Cls (5 cls):\", svc_5_cls.score(test_X, test_y_5_cls))\n",
    "# print(\"Reg (10 cls):\", accuracy_score(test_y_10_cls, svr_y_10_cls))\n",
    "# print(\"Cls (10 cls):\", svc_10_cls.score(test_X, test_y_10_cls))\n",
    "# print(\"Reg (20 cls):\", accuracy_score(test_y_20_cls, svr_y_20_cls))\n",
    "# print(\"Cls (20 cls):\", svc_20_cls.score(test_X, test_y_20_cls))\n",
    "\n",
    "print(\"Test MSE\")\n",
    "print(\"Reg:\", mean_squared_error(svr.predict(test_X), test_y))\n",
    "print(\"Cls (5 cls):\", mean_squared_error(test_y_5_pred, test_y_5_cls.apply(cls_5_to_value)))\n",
    "# print(\"Cls (10 cls):\", mean_squared_error(test_y_10_pred, test_y_10_cls.apply(cls_10_to_value)))\n",
    "# print(\"Cls (20 cls):\", mean_squared_error(test_y_20_pred, test_y_20_cls.apply(cls_20_to_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "work"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
