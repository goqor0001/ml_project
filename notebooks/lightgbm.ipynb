{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, anneal, Trials\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "random_state=42\n",
    "num_folds=2\n",
    "kf = KFold(n_splits=num_folds, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../data/train_final.csv')\n",
    "val_data = pd.read_csv('../data/val_final.csv')\n",
    "test_data = pd.read_csv('../data/test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_data, val_data, test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15080, 5910)\n",
      "(3770, 5910)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "train_X = train_data.drop(columns=['posterID','imdb_score'])\n",
    "test_X = test_data.drop(columns=['posterID','imdb_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(map(str, range(len(train_X.columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.columns = cols\n",
    "test_X.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_mse_cv(params, random_state=random_state, cv=kf, X=train_X, y=train_data['imdb_score']):\n",
    "    # the function gets a set of variable parameters in \"param\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'learning_rate': params['learning_rate']}\n",
    "    \n",
    "    # we use this params to create a new LGBM Regressor\n",
    "    model = lgb.LGBMRegressor(random_state=random_state, **params)\n",
    "    \n",
    "    # and then conduct the cross validation with the same folds as before\n",
    "    score = -cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:12<00:00, 25.24s/trial, best loss: 0.883686585070359]\n",
      "Best MSE 0.884 params {'learning_rate': 0.009516355818546441, 'max_depth': 17.0, 'n_estimators': 964.0}\n",
      "CPU times: user 1min 22s, sys: 3.76 s, total: 1min 26s\n",
      "Wall time: 4min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_iter = 10\n",
    "# possible values of parameters\n",
    "space={'n_estimators': hp.quniform('n_estimators', 100, 2000, 1),\n",
    "       'max_depth' : hp.quniform('max_depth', 2, 20, 1),\n",
    "       'learning_rate': hp.loguniform('learning_rate', -5, 0)\n",
    "      }\n",
    "\n",
    "# trials will contain logging information\n",
    "trials = Trials()\n",
    "\n",
    "best=fmin(fn=gb_mse_cv, # function to optimize\n",
    "          space=space, \n",
    "          algo=tpe.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          max_evals=n_iter, # maximum number of iterations\n",
    "          trials=trials, # logging\n",
    "          rstate=np.random.RandomState(random_state) # fixing random state for the reproducibility\n",
    "         )\n",
    "\n",
    "# computing the score on the test set\n",
    "model = lgb.LGBMRegressor(random_state=random_state, n_estimators=int(best['n_estimators']),\n",
    "                      max_depth=int(best['max_depth']),learning_rate=best['learning_rate'])\n",
    "model.fit(train_X, train_data['imdb_score'])\n",
    "tpe_test_score=mean_squared_error(test_data['imdb_score'], model.predict(test_X))\n",
    "\n",
    "print(\"Best MSE {:.3f} params {}\".format( gb_mse_cv(best), best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mse of prediction on test is:  0.8067169142666126\n",
      "r2 score on test is:  0.4513371218065787\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_X)\n",
    "print('The mse of prediction on test is: ', mean_squared_error(test_data['imdb_score'], y_pred))\n",
    "print('r2 score on test is: ', r2_score(test_data['imdb_score'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7fec499232d0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.booster_.save_model('lightgbm_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = lgb.Booster(model_file='lightgbm_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mse of prediction on test is:  0.8067169142666126\n",
      "r2 score on test is:  0.4513371218065787\n"
     ]
    }
   ],
   "source": [
    "y_pred = reg.predict(test_X)\n",
    "print('The mse of prediction on test is: ', mean_squared_error(test_data['imdb_score'], y_pred))\n",
    "print('r2 score on test is: ', r2_score(test_data['imdb_score'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mse of prediction on train is:  0.648812785414066\n",
      "r2 score on train is:  0.5592180572657477\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = model.predict(train_X)\n",
    "print('The mse of prediction on train is: ', mean_squared_error(train_data['imdb_score'], y_pred1))\n",
    "print('r2 score on train is: ', r2_score(train_data['imdb_score'], y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
